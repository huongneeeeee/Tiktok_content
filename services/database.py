# services/database.py
"""
TikVault Database Service
Handles MongoDB collections and Qdrant vector database
"""

import os
import sys
import hashlib
import requests
import json
from datetime import datetime
from typing import Optional, Dict, List, Any
from pymongo import MongoClient, ASCENDING, DESCENDING, TEXT
from pymongo.collection import Collection
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance
from sentence_transformers import SentenceTransformer, CrossEncoder
from langchain_text_splitters import RecursiveCharacterTextSplitter

# Import Config
try:
    from config import Config
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from config import Config

_global_model = None
_global_reranker = None


class TikVaultDB:
    """
    Database service cho TikVault
    Qu·∫£n l√Ω 4 MongoDB collections + Qdrant vector DB
    """
    
    def __init__(self):
        print("   üîπ [INIT] ƒêang kh·ªüi ƒë·ªông Database Service...")
        
        self.mongo_uri = Config.MONGO_URI
        self.db = None
        
        # MongoDB Collections
        self.users: Optional[Collection] = None
        self.videos: Optional[Collection] = None
        self.categories: Optional[Collection] = None
        self.search_logs: Optional[Collection] = None
        self.user_collections: Optional[Collection] = None  # Knowledge collections
        
        self._connect_mongo()
        
        # Qdrant Vector DB
        self.vector_collection = "video_chunks_bge_m3"
        self.qdrant_client = self._connect_qdrant()
        
        # ML Models
        self.model_path = os.path.join(Config.MODEL_DIR, "bge-m3")
        self.model = self._load_model()
        self.reranker = self._load_reranker()
        
        # Text Splitter for chunking
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500, chunk_overlap=50, 
            separators=["\n\n", "\n", ". ", " ", ""]
        )
    
    # ================================================
    # CONNECTION METHODS
    # ================================================
    
    def _connect_mongo(self):
        """K·∫øt n·ªëi MongoDB v√† t·∫°o c√°c collections v·ªõi indexes"""
        try:
            client = MongoClient(self.mongo_uri, serverSelectionTimeoutMS=3000)
            client.server_info()
            
            self.db = client["tikvault_db"]
            
            # Init collections
            self.users = self.db["users"]
            self.videos = self.db["videos"]
            self.categories = self.db["categories"]
            self.search_logs = self.db["search_logs"]
            self.user_collections = self.db["user_collections"]
            
            # Create indexes
            self._create_indexes()
            
            # Seed default categories if empty
            self._seed_categories()
            
            print("   ‚úÖ [MONGO] Connected to tikvault_db")
            
        except Exception as e:
            print(f"   ‚ùå L·ªói k·∫øt n·ªëi MongoDB: {e}")
    
    def _create_indexes(self):
        """T·∫°o indexes cho t·∫•t c·∫£ collections"""
        try:
            # Users indexes
            self.users.create_index("email", unique=True)
            self.users.create_index([("oauth_provider", 1), ("oauth_id", 1)], sparse=True)
            
            # Videos indexes
            self.videos.create_index("video_id", unique=True)
            self.videos.create_index("user_id")
            self.videos.create_index("ai_analysis.classification.level_1")
            self.videos.create_index([("processed_at", DESCENDING)])
            self.videos.create_index([("title", TEXT), ("transcript", TEXT)])
            
            # Categories indexes
            self.categories.create_index("key", unique=True)
            self.categories.create_index([("order", ASCENDING)])
            
            # Search logs indexes
            self.search_logs.create_index("user_id")
            self.search_logs.create_index([("created_at", DESCENDING)])
            
            # User collections indexes
            self.user_collections.create_index("user_id")
            self.user_collections.create_index([("updated_at", DESCENDING)])
            self.search_logs.create_index([("query", TEXT)])
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Index creation warning: {e}")
    
    def _seed_categories(self):
        """Seed default categories n·∫øu collection tr·ªëng - v2.0 (8 categories)"""
        if self.categories.count_documents({}) > 0:
            return
        
        default_categories = [
            {
                "key": "H·ªåC_H·ªéI",
                "name": "H·ªçc H·ªèi",
                "description": "Videos d·∫°y k·ªπ nƒÉng, ki·∫øn th·ª©c c√≥ th·ªÉ h·ªçc h·ªèi v√† √°p d·ª•ng",
                "icon": "fa-graduation-cap",
                "color": "#3b82f6",
                "order": 1,
                "subcategories": [
                    {"key": "Tutorial", "name": "Tutorial", "tags": ["H∆∞·ªõng_d·∫´n", "How_to", "DIY"]},
                    {"key": "Ng√¥n_Ng·ªØ", "name": "Ng√¥n Ng·ªØ", "tags": ["Ti·∫øng_Anh", "H√†n", "Nh·∫≠t", "T·ª´_v·ª±ng"]},
                    {"key": "Tech_Review", "name": "Tech Review", "tags": ["C√¥ng_ngh·ªá", "App", "Unboxing"]},
                    {"key": "M·∫πo_Hay", "name": "M·∫πo Hay", "tags": ["Life_hacks", "Tips", "Ti·∫øt_ki·ªám"]},
                    {"key": "Ki·∫øn_Th·ª©c", "name": "Ki·∫øn Th·ª©c", "tags": ["Khoa_h·ªçc", "L·ªãch_s·ª≠", "Facts"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "·∫®M_TH·ª∞C",
                "name": "·∫®m Th·ª±c",
                "description": "M·ªçi th·ª© li√™n quan ƒë·∫øn ƒÉn u·ªëng, n·∫•u n∆∞·ªõng",
                "icon": "fa-utensils",
                "color": "#f59e0b",
                "order": 2,
                "subcategories": [
                    {"key": "C√¥ng_Th·ª©c", "name": "C√¥ng Th·ª©c", "tags": ["Recipe", "M√≥n_ƒÉn", "L√†m_b√°nh"]},
                    {"key": "Review_Qu√°n", "name": "Review Qu√°n", "tags": ["ƒê·ªãa_ƒëi·ªÉm_ƒÉn", "Street_food", "Qu√°n_m·ªõi"]},
                    {"key": "M·∫πo_B·∫øp", "name": "M·∫πo B·∫øp", "tags": ["Tips_n·∫•u_ƒÉn", "B·∫£o_qu·∫£n", "Dinh_d∆∞·ª°ng"]},
                    {"key": "ƒê·ªì_U·ªëng", "name": "ƒê·ªì U·ªëng", "tags": ["C√†_ph√™", "Tr√†_s·ªØa", "Cocktail"]},
                    {"key": "Mukbang", "name": "Mukbang", "tags": ["ASMR", "Th·ª≠_th√°ch_ƒÉn", "Food_challenge"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "PHONG_C√ÅCH",
                "name": "Phong C√°ch",
                "description": "Th·ªùi trang, l√†m ƒë·∫πp, chƒÉm s√≥c b·∫£n th√¢n",
                "icon": "fa-wand-magic-sparkles",
                "color": "#ec4899",
                "order": 3,
                "subcategories": [
                    {"key": "Outfit", "name": "Outfit", "tags": ["OOTD", "Ph·ªëi_ƒë·ªì", "GRWM"]},
                    {"key": "Makeup", "name": "Makeup", "tags": ["Trang_ƒëi·ªÉm", "Tutorial", "Bi·∫øn_h√¨nh"]},
                    {"key": "Skincare", "name": "Skincare", "tags": ["ChƒÉm_da", "Review_m·ªπ_ph·∫©m", "Routine"]},
                    {"key": "T√≥c_Nail", "name": "T√≥c & Nail", "tags": ["Ki·ªÉu_t√≥c", "Nail_art", "Nhu·ªôm_t√≥c"]},
                    {"key": "Review_SP", "name": "Review SP", "tags": ["Th·ªùi_trang", "M·ªπ_ph·∫©m", "Haul"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "KH√ÅM_PH√Å",
                "name": "Kh√°m Ph√°",
                "description": "Du l·ªãch, ƒë·ªãa ƒëi·ªÉm, tr·∫£i nghi·ªám m·ªõi l·∫°",
                "icon": "fa-earth-asia",
                "color": "#10b981",
                "order": 4,
                "subcategories": [
                    {"key": "ƒêi·ªÉm_ƒê·∫øn", "name": "ƒêi·ªÉm ƒê·∫øn", "tags": ["Check_in", "Hidden_gems", "C·∫£nh_ƒë·∫πp"]},
                    {"key": "L∆∞u_Tr√∫", "name": "L∆∞u Tr√∫", "tags": ["Kh√°ch_s·∫°n", "Resort", "Homestay"]},
                    {"key": "Tr·∫£i_Nghi·ªám", "name": "Tr·∫£i Nghi·ªám", "tags": ["Tour", "Camping", "Ph∆∞·ª£t"]},
                    {"key": "·∫®m_Th·ª±c_Local", "name": "·∫®m Th·ª±c Local", "tags": ["ƒê·∫∑c_s·∫£n", "Food_tour", "ƒÇn_v√πng_mi·ªÅn"]},
                    {"key": "Tips_Du_L·ªãch", "name": "Tips Du L·ªãch", "tags": ["Kinh_nghi·ªám", "Packing", "Budget"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "ƒê·ªúI_TH∆Ø·ªúNG",
                "name": "ƒê·ªùi Th∆∞·ªùng",
                "description": "Chia s·∫ª cu·ªôc s·ªëng, vlog, c√¢u chuy·ªán h√†ng ng√†y",
                "icon": "fa-house",
                "color": "#8b5cf6",
                "order": 5,
                "subcategories": [
                    {"key": "Vlog", "name": "Vlog", "tags": ["Daily_life", "BTS", "M·ªôt_ng√†y"]},
                    {"key": "Gia_ƒê√¨nh", "name": "Gia ƒê√¨nh", "tags": ["Parenting", "Baby", "Th√∫_c∆∞ng"]},
                    {"key": "T√¢m_S·ª±", "name": "T√¢m S·ª±", "tags": ["Chia_s·∫ª", "Advice", "Confession"]},
                    {"key": "C√¥ng_S·ªü", "name": "C√¥ng S·ªü", "tags": ["Career", "WFH", "Ph·ªèng_v·∫•n"]},
                    {"key": "Tin_T·ª©c", "name": "Tin T·ª©c", "tags": ["Th·ªùi_s·ª±", "Xu_h∆∞·ªõng", "C·∫≠p_nh·∫≠t"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "GI·∫¢I_TR√ç",
                "name": "Gi·∫£i Tr√≠",
                "description": "Xem cho vui, th∆∞ gi√£n, n·ªôi dung gi·∫£i tr√≠ thu·∫ßn t√∫y",
                "icon": "fa-face-laugh",
                "color": "#f472b6",
                "order": 6,
                "subcategories": [
                    {"key": "H√†i", "name": "H√†i", "tags": ["Comedy", "Prank", "POV_h√†i"]},
                    {"key": "Nh·∫°c_Dance", "name": "Nh·∫°c & Dance", "tags": ["Cover", "V≈©_ƒë·∫°o", "Challenge"]},
                    {"key": "Phim_Game", "name": "Phim & Game", "tags": ["Review_phim", "Gaming", "Esports"]},
                    {"key": "Trend", "name": "Trend", "tags": ["Meme", "Viral", "CapCut"]},
                    {"key": "Pets", "name": "Pets", "tags": ["ƒê·ªông_v·∫≠t", "Cute", "Funny"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "C·∫¢M_X√öC",
                "name": "C·∫£m X√∫c",
                "description": "N·ªôi dung thi√™n v·ªÅ c·∫£m x√∫c, t√¢m tr·∫°ng, mood",
                "icon": "fa-heart",
                "color": "#a855f7",
                "order": 7,
                "subcategories": [
                    {"key": "Chill", "name": "Chill", "tags": ["Aesthetic", "Lofi", "Th∆∞_gi√£n"]},
                    {"key": "Motivation", "name": "Motivation", "tags": ["ƒê·ªông_l·ª±c", "Quotes", "NƒÉng_l∆∞·ª£ng"]},
                    {"key": "T√¨nh_Y√™u", "name": "T√¨nh Y√™u", "tags": ["Couple", "Chia_tay", "Crush"]},
                    {"key": "Healing", "name": "Healing", "tags": ["Ch·ªØa_l√†nh", "Self_care", "An_·ªßi"]},
                    {"key": "Throwback", "name": "Throwback", "tags": ["Ho√†i_ni·ªám", "K·ª∑_ni·ªám", "Nostalgia"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            },
            {
                "key": "KH√ÅC",
                "name": "Kh√°c",
                "description": "Video kh√¥ng thu·ªôc danh m·ª•c n√†o ho·∫∑c kh√¥ng c√≥ gi√° tr·ªã",
                "icon": "fa-box",
                "color": "#6b7280",
                "order": 8,
                "subcategories": [
                    {"key": "Qu·∫£ng_C√°o", "name": "Qu·∫£ng C√°o", "tags": ["Sponsored", "Ads", "Promote"]},
                    {"key": "Kh√¥ng_R√µ", "name": "Kh√¥ng R√µ", "tags": ["Ch∆∞a_ph√¢n_lo·∫°i", "M∆°_h·ªì"]},
                    {"key": "R√°c", "name": "R√°c", "tags": ["Spam", "L·ªói", "Test"]}
                ],
                "is_active": True,
                "created_at": datetime.utcnow()
            }
        ]
        
        try:
            self.categories.insert_many(default_categories)
            print("   ‚úÖ [MONGO] Seeded default categories")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Category seeding warning: {e}")
    
    def _connect_qdrant(self):
        """K·∫øt n·ªëi Qdrant vector database"""
        try:
            client = QdrantClient(host=Config.QDRANT_HOST, port=Config.QDRANT_PORT)
            try:
                collections = client.get_collections()
                exists = any(c.name == self.vector_collection for c in collections.collections)
                if not exists:
                    client.create_collection(
                        collection_name=self.vector_collection,
                        vectors_config=VectorParams(size=1024, distance=Distance.COSINE),
                    )
                    print(f"   ‚úÖ [QDRANT] Created collection: {self.vector_collection}")
            except:
                pass
            return client
        except Exception as e:
            print(f"   ‚ùå L·ªói k·∫øt n·ªëi Qdrant: {e}")
            return None
    
    def _load_model(self):
        """Load embedding model"""
        global _global_model
        if _global_model:
            return _global_model
        
        print(f"   üîπ [EMBED] ƒêang kh·ªüi t·∫°o model Embedding...")
        try:
            if os.path.exists(self.model_path):
                print(f"   -> Load local: {self.model_path}")
                model = SentenceTransformer(self.model_path)
            else:
                print(f"   -> Load HuggingFace (BAAI/bge-m3)...")
                model = SentenceTransformer('BAAI/bge-m3')
                model.save(self.model_path)
            _global_model = model
            print("   ‚úÖ ƒê√£ load xong model Embedding.")
            return model
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i Model: {e}")
            return None
    
    def _load_reranker(self):
        """Load reranker model"""
        global _global_reranker
        if _global_reranker:
            return _global_reranker
        try:
            print("   üîπ [RERANK] ƒêang t·∫£i model Reranker...")
            reranker = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2-v2')
            _global_reranker = reranker
            return reranker
        except:
            return None
    
    # ================================================
    # VIDEO METHODS
    # ================================================
    
    def save_video(self, video_data: Dict, user_id: str = None) -> bool:
        """L∆∞u video v√†o MongoDB v√† Qdrant"""
        video_id = video_data.get("id") or video_data.get("video_id")
        if not video_id:
            return False
        
        # Chu·∫©n h√≥a document
        now = datetime.utcnow()
        doc = {
            "video_id": str(video_id),
            "user_id": user_id,
            "type": video_data.get("type", "video"),
            "title": video_data.get("title", ""),
            "original_url": video_data.get("original_url", ""),
            "filename": video_data.get("filename", ""),
            "author": video_data.get("author", {}),
            "stats": video_data.get("stats", {}),
            "transcript": video_data.get("transcript", ""),
            "hashtags": video_data.get("hashtags", []),
            "ai_analysis": video_data.get("ai_analysis", {}),
            "ocr_data": video_data.get("ocr_data", {}),  # OCR data from PaddleOCR
            "drive_links": video_data.get("drive_links", {}),
            "local_path": video_data.get("local_path", ""),
            "is_slideshow": video_data.get("is_slideshow", False),
            "slideshow_images": video_data.get("slideshow_images", []),
            "thumbnail": video_data.get("thumbnail"),
            "duration": video_data.get("duration"),
            "music_title": video_data.get("music_title"),
            "create_time": video_data.get("create_time"),
            "processed_at": video_data.get("processed_at", now),
            "updated_at": now
        }
        
        # Save to MongoDB
        if self.videos is not None:
            try:
                self.videos.update_one(
                    {"video_id": str(video_id)},
                    {"$set": doc},
                    upsert=True
                )
            except Exception as e:
                print(f"   ‚ùå L·ªói Mongo Write: {e}")
        
        # Save to Qdrant
        if self.qdrant_client is not None and self.model:
            self._save_video_embeddings(video_id, video_data)
        
        return True
    
    def _save_video_embeddings(self, video_id: str, video_data: Dict):
        """
        L∆∞u embeddings v√†o Qdrant v·ªõi Knowledge Card data.
        
        Strategy: Embed summary + key_takeaways instead of raw transcript
        ‚Üí Better search quality, less noise, more focused results
        """
        try:
            ai_analysis = video_data.get('ai_analysis', {})
            knowledge_card = ai_analysis.get('knowledge_card', {})
            
            # Get Knowledge Card fields
            kc_title = knowledge_card.get('title', video_data.get('title', ''))
            kc_summary = knowledge_card.get('summary', ai_analysis.get('summary', ''))
            kc_takeaways = knowledge_card.get('key_takeaways', [])
            kc_action_items = knowledge_card.get('action_items', [])
            kc_tags = knowledge_card.get('tags', [])
            category_path = knowledge_card.get('category_path', '') or ai_analysis.get('classification', {}).get('category_path', '')
            
            # Scores
            scores = ai_analysis.get('scores', {})
            knowledge_density = scores.get('knowledge_density', knowledge_card.get('knowledge_density', 5))
            actionability = scores.get('actionability', knowledge_card.get('actionability', 5))
            
            # Build semantic content for embedding
            # Format: Title + Category + Summary + Key Takeaways + Tags + OCR
            takeaways_text = "; ".join(kc_takeaways) if kc_takeaways else ""
            actions_text = "; ".join(kc_action_items) if kc_action_items else ""
            tags_text = ", ".join(kc_tags) if kc_tags else ""
            
            # Get OCR text if available (NEW)
            ocr_data = video_data.get("ocr_data", {})
            ocr_text = ocr_data.get("ocr_text", "")[:500] if ocr_data else ""  # Limit to 500 chars
            
            # Primary chunk: Summary + Key Takeaways + OCR (most important for search)
            primary_content = f"""
Ti√™u ƒë·ªÅ: {kc_title}
Danh m·ª•c: {category_path}
T√≥m t·∫Øt: {kc_summary}
ƒêi·ªÉm ch√≠nh: {takeaways_text}
Tags: {tags_text}
""".strip()
            
            # Add OCR text to primary content if available
            if ocr_text:
                primary_content += f"\nText tr√™n m√†n h√¨nh: {ocr_text}"
            
            # Optional: Action items as second chunk if substantial
            chunks_to_embed = [primary_content]
            if actions_text and len(kc_action_items) >= 3:
                action_chunk = f"""
Ti√™u ƒë·ªÅ: {kc_title}
H∆∞·ªõng d·∫´n th·ª±c hi·ªán: {actions_text}
Danh m·ª•c: {category_path}
""".strip()
                chunks_to_embed.append(action_chunk)
            
            # Build Qdrant points
            points = []
            for idx, content in enumerate(chunks_to_embed):
                vector = self.get_embedding(content)
                
                payload = {
                    "video_id": str(video_id),
                    "title": video_data.get("title"),
                    "refined_title": kc_title,
                    "author": video_data.get("author", {}),
                    "chunk_text": content,
                    "summary": kc_summary,
                    "key_takeaways": kc_takeaways,
                    "filename": video_data.get("filename"),
                    "drive_links": video_data.get("drive_links", {}),
                    "stats": video_data.get("stats", {}),
                    "category_path": category_path,
                    "category_l1": ai_analysis.get("classification", {}).get("level_1", ""),
                    "knowledge_density": knowledge_density,
                    "actionability": actionability,
                    "tags": kc_tags
                }
                
                point_id = self._get_chunk_id(video_id, idx)
                points.append(PointStruct(id=point_id, vector=vector, payload=payload))
            
            if points:
                self.qdrant_client.upsert(
                    collection_name=self.vector_collection,
                    points=points
                )
                print(f"   ‚úÖ [DB] Saved {len(points)} Knowledge Card chunks to Qdrant.")
                
        except Exception as e:
            print(f"   ‚ùå L·ªói Qdrant Write: {e}")
    
    def get_video(self, video_id: str) -> Optional[Dict]:
        """L·∫•y video theo ID"""
        if not self.videos:
            return None
        return self.videos.find_one({"video_id": str(video_id)})
    
    def get_videos_by_user(self, user_id: str, limit: int = 50) -> List[Dict]:
        """L·∫•y danh s√°ch video c·ªßa user"""
        if not self.videos:
            return []
        return list(self.videos.find(
            {"user_id": user_id}
        ).sort("processed_at", DESCENDING).limit(limit))
    
    def get_videos_by_category(self, category_key: str, limit: int = 50) -> List[Dict]:
        """L·∫•y videos theo category"""
        if not self.videos:
            return []
        return list(self.videos.find(
            {"ai_analysis.classification.level_1": category_key}
        ).sort("processed_at", DESCENDING).limit(limit))
    
    # ================================================
    # SEARCH METHODS
    # ================================================
    
    def _get_chunk_id(self, video_id_str, chunk_index):
        """Generate chunk ID t·ª´ video_id v√† chunk index"""
        raw_key = f"{video_id_str}_{chunk_index}"
        hex_digest = hashlib.md5(raw_key.encode('utf-8')).hexdigest()
        return int(hex_digest, 16) % (2**64)
    
    def get_embedding(self, text: str) -> List[float]:
        """Get embedding vector t·ª´ text"""
        if not text or not self.model:
            return [0.0] * 1024
        return self.model.encode(text).tolist()
    
    def search_videos(self, query_text: str, user_id: str = None, limit: int = 3) -> List[Dict]:
        """
        Hybrid Search: Qdrant semantic search + MongoDB metadata lookup
        1. Get relevant video_ids from Qdrant vector search
        2. Fetch full metadata from MongoDB
        3. Return top results with complete information
        """
        if self.qdrant_client is None or self.videos is None:
            print("‚ùå Search unavailable: Qdrant or MongoDB not connected")
            return []
        
        print(f"üîé Hybrid Search: {query_text}")
        
        try:
            # Step 1: Get embedding for query
            query_vector = self.get_embedding(query_text)
            qdrant_results = []
            
            # Step 2: Search in Qdrant for relevant video chunks
            try:
                qdrant_results = self.qdrant_client.search(
                    collection_name=self.vector_collection,
                    query_vector=query_vector,
                    limit=limit * 3  # Get more to deduplicate
                )
            except AttributeError:
                # Fallback to REST API
                print("   ‚ö†Ô∏è Lib Error: Fallback to HTTP API...")
                url = f"http://{Config.QDRANT_HOST}:{Config.QDRANT_PORT}/collections/{self.vector_collection}/points/search"
                payload = {
                    "vector": query_vector,
                    "limit": limit * 3,
                    "with_payload": True
                }
                response = requests.post(url, json=payload)
                if response.status_code == 200:
                    data = response.json()
                    from types import SimpleNamespace
                    for item in data.get('result', []):
                        hit = SimpleNamespace()
                        hit.score = item.get('score')
                        hit.payload = item.get('payload', {})
                        qdrant_results.append(hit)
            
            if not qdrant_results:
                print("   ‚ö†Ô∏è No Qdrant results, falling back to MongoDB text search")
                # Fallback: Simple MongoDB text search
                mongo_results = list(self.videos.find(
                    {"$text": {"$search": query_text}}
                ).limit(limit))
                
                # If no text index, try regex search on title
                if not mongo_results:
                    import re
                    mongo_results = list(self.videos.find({
                        "$or": [
                            {"title": {"$regex": query_text, "$options": "i"}},
                            {"transcript": {"$regex": query_text, "$options": "i"}}
                        ]
                    }).limit(limit))
                
                return self._format_mongo_results(mongo_results)
            
            # Step 3: Detect category intent from query
            # Map keywords to categories for category-aware filtering
            CATEGORY_KEYWORDS = {
                # KI·∫æN_TH·ª®C
                "tin t·ª©c": ("KI·∫æN_TH·ª®C", "Tin_t·ª©c"),
                "th·ªùi s·ª±": ("KI·∫æN_TH·ª®C", "Tin_t·ª©c"),
                "news": ("KI·∫æN_TH·ª®C", "Tin_t·ª©c"),
                "review": ("KI·∫æN_TH·ª®C", "Review_S·∫£n_ph·∫©m"),
                "ƒë√°nh gi√°": ("KI·∫æN_TH·ª®C", "Review_S·∫£n_ph·∫©m"),
                "m·∫πo": ("KI·∫æN_TH·ª®C", "M·∫πo_v·∫∑t"),
                "tips": ("KI·∫æN_TH·ª®C", "M·∫πo_v·∫∑t"),
                "h∆∞·ªõng d·∫´n": ("KI·∫æN_TH·ª®C", "Gi√°o_d·ª•c"),
                "h·ªçc": ("KI·∫æN_TH·ª®C", "Gi√°o_d·ª•c"),
                # ·∫®M_TH·ª∞C
                "n·∫•u ƒÉn": ("·∫®M_TH·ª∞C", "N·∫•u_ƒÉn"),
                "c√¥ng th·ª©c": ("·∫®M_TH·ª∞C", "N·∫•u_ƒÉn"),
                "c√°ch l√†m": ("·∫®M_TH·ª∞C", "N·∫•u_ƒÉn"),
                "m√≥n ƒÉn": ("·∫®M_TH·ª∞C", "N·∫•u_ƒÉn"),
                "b√°nh": ("·∫®M_TH·ª∞C", "N·∫•u_ƒÉn"),
                "qu√°n": ("·∫®M_TH·ª∞C", "Review_Qu√°n"),
                "nh√† h√†ng": ("·∫®M_TH·ª∞C", "Review_Qu√°n"),
                "mukbang": ("·∫®M_TH·ª∞C", "Mukbang"),
                # ƒê·ªúI_S·ªêNG
                "outfit": ("ƒê·ªúI_S·ªêNG", "Phong_c√°ch"),
                "ph·ªëi ƒë·ªì": ("ƒê·ªúI_S·ªêNG", "Phong_c√°ch"),
                "th·ªùi trang": ("ƒê·ªúI_S·ªêNG", "Phong_c√°ch"),
                "ootd": ("ƒê·ªúI_S·ªêNG", "Phong_c√°ch"),
                "vlog": ("ƒê·ªúI_S·ªêNG", "Vlog_ƒê·ªùi_th∆∞·ªùng"),
                # DU_L·ªäCH
                "du l·ªãch": ("DU_L·ªäCH", "ƒê·ªãa_ƒëi·ªÉm"),
                "ƒëi ch∆°i": ("DU_L·ªäCH", "ƒê·ªãa_ƒëi·ªÉm"),
                "check in": ("DU_L·ªäCH", "ƒê·ªãa_ƒëi·ªÉm"),
                "resort": ("DU_L·ªäCH", "Resort_Kh√°ch_s·∫°n"),
                "kh√°ch s·∫°n": ("DU_L·ªäCH", "Resort_Kh√°ch_s·∫°n"),
                "kinh nghi·ªám ƒëi": ("DU_L·ªäCH", "Kinh_nghi·ªám"),
                # GI·∫¢I_TR√ç
                "h√†i": ("GI·∫¢I_TR√ç", "H√†i_h∆∞·ªõc"),
                "funny": ("GI·∫¢I_TR√ç", "H√†i_h∆∞·ªõc"),
                "game": ("GI·∫¢I_TR√ç", "Game"),
                "phim": ("GI·∫¢I_TR√ç", "Phim_·∫£nh"),
                "nh·∫£y": ("GI·∫¢I_TR√ç", "Tr√¨nh_di·ªÖn"),
                "dance": ("GI·∫¢I_TR√ç", "Tr√¨nh_di·ªÖn"),
                # C·∫¢M_X√öC
                "chill": ("C·∫¢M_X√öC", "Chill"),
                "ƒë·ªông l·ª±c": ("C·∫¢M_X√öC", "ƒê·ªông_l·ª±c"),
                "motivation": ("C·∫¢M_X√öC", "ƒê·ªông_l·ª±c"),
            }
            
            # Detect category from query
            query_lower = query_text.lower()
            detected_category = None
            detected_subcategory = None
            
            for keyword, (cat, subcat) in CATEGORY_KEYWORDS.items():
                if keyword in query_lower:
                    detected_category = cat
                    detected_subcategory = subcat
                    print(f"   üìÇ Detected category intent: {cat} > {subcat}")
                    break
            
            # Step 4: Extract unique video_ids with best scores
            # Higher threshold to filter truly irrelevant results
            MIN_SCORE_THRESHOLD = 0.45  # Slightly lower to allow category filtering
            
            video_scores = {}
            video_categories = {}  # Track categories for each video
            
            for hit in qdrant_results:
                vid_id = hit.payload.get("video_id") or hit.payload.get("id")
                score = hit.score
                
                # Only include results above threshold
                if vid_id and score >= MIN_SCORE_THRESHOLD:
                    if vid_id not in video_scores or score > video_scores[vid_id]:
                        video_scores[vid_id] = score
                        # Store category info from payload if available
                        video_categories[vid_id] = hit.payload.get("category_l1", "")
            
            # If no results pass threshold, lower it slightly for best match only
            if not video_scores and qdrant_results:
                best_hit = max(qdrant_results, key=lambda x: x.score)
                if best_hit.score >= 0.35:  # At least 35% for fallback
                    vid_id = best_hit.payload.get("video_id") or best_hit.payload.get("id")
                    if vid_id:
                        video_scores[vid_id] = best_hit.score
                        print(f"   ‚ö†Ô∏è Fallback: Using best match with {best_hit.score*100:.0f}% score")
            
            # Step 5: Fetch metadata and apply category filtering
            results_with_meta = []
            for vid_id, score in video_scores.items():
                video_doc = self.videos.find_one({"video_id": vid_id})
                if video_doc:
                    # Get video's category
                    ai_analysis = video_doc.get("ai_analysis", {})
                    classification = ai_analysis.get("classification", {})
                    video_cat = classification.get("level_1", "")
                    video_subcat = classification.get("level_2", "")
                    
                    # Boost score if category matches detected intent
                    boost = 1.0
                    if detected_category:
                        if video_cat == detected_category:
                            boost = 1.3  # 30% boost for matching category
                            if video_subcat == detected_subcategory:
                                boost = 1.5  # 50% boost for exact subcategory match
                        else:
                            boost = 0.5  # Penalize non-matching categories
                    
                    adjusted_score = score * boost
                    
                    results_with_meta.append({
                        "video_id": vid_id,
                        "original_score": score,
                        "score": adjusted_score,
                        "video_doc": video_doc,
                        "category_match": video_cat == detected_category if detected_category else True
                    })
            
            # Sort by adjusted score and filter
            results_with_meta.sort(key=lambda x: x["score"], reverse=True)
            
            # If category was detected, ONLY return videos that match the category
            if detected_category:
                matching_results = [r for r in results_with_meta if r["category_match"]]
                if matching_results:
                    top_results = matching_results[:limit]
                    print(f"   ‚úÖ Filtered to {len(top_results)} videos matching category: {detected_category}")
                else:
                    # No exact matches, show best results with warning
                    top_results = results_with_meta[:limit]
                    print(f"   ‚ö†Ô∏è No videos in category {detected_category}, showing best available")
            else:
                top_results = results_with_meta[:limit]
            
            # Log filtering stats
            original_count = len(qdrant_results)
            print(f"   ‚Üí Found {len(top_results)} relevant videos (from {original_count} candidates, threshold {MIN_SCORE_THRESHOLD*100:.0f}%)")
            
            # Step 6: Format results for return
            results = []
            for item in top_results:
                video_doc = item["video_doc"]
                results.append({
                    "video_id": item["video_id"],
                    "score": item["score"],
                    "title": video_doc.get("title", ""),
                    "author": video_doc.get("author", {}),
                    "transcript": video_doc.get("transcript", ""),  # Full transcript for RAG
                    "thumbnail": video_doc.get("thumbnail"),
                    "filename": video_doc.get("filename"),
                    "is_slideshow": video_doc.get("is_slideshow", False),
                    "slideshow_images": video_doc.get("slideshow_images", []),
                    "stats": video_doc.get("stats", {}),
                    "ai_analysis": video_doc.get("ai_analysis", {}),
                    "drive_links": video_doc.get("drive_links", {}),
                    "duration": video_doc.get("duration"),
                    "original_url": video_doc.get("original_url")
                })
            
            print(f"   ‚úÖ Returning {len(results)} videos with full metadata")
            return results
            
        except Exception as e:
            print(f"‚ùå Hybrid Search Error: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _format_mongo_results(self, mongo_results: List) -> List[Dict]:
        """Format MongoDB results for fallback search"""
        results = []
        for doc in mongo_results:
            results.append({
                "video_id": doc.get("video_id"),
                "score": 1.0,  # Default score for text search
                "title": doc.get("title", ""),
                "author": doc.get("author", {}),
                "transcript": doc.get("transcript", "")[:200] + "..." if doc.get("transcript") else "",
                "thumbnail": doc.get("thumbnail"),
                "filename": doc.get("filename"),
                "is_slideshow": doc.get("is_slideshow", False),
                "slideshow_images": doc.get("slideshow_images", []),
                "stats": doc.get("stats", {}),
                "ai_analysis": doc.get("ai_analysis", {}),
                "drive_links": doc.get("drive_links", {}),
                "duration": doc.get("duration"),
                "original_url": doc.get("original_url")
            })
        return results
    
    def _log_search(self, query: str, user_id: str, hits: List):
        """Log search query for analytics"""
        if self.search_logs is None:
            return
        try:
            self.search_logs.insert_one({
                "user_id": user_id,
                "query": query,
                "results_count": len(hits),
                "result_ids": [h.get("video_id") for h in hits if isinstance(h, dict)],
                "created_at": datetime.utcnow()
            })
        except:
            pass
    
    # ================================================
    # CATEGORY METHODS
    # ================================================
    
    def get_categories(self, active_only: bool = True) -> List[Dict]:
        """L·∫•y danh s√°ch categories"""
        if not self.categories:
            return []
        query = {"is_active": True} if active_only else {}
        return list(self.categories.find(query).sort("order", ASCENDING))
    
    def get_category(self, key: str) -> Optional[Dict]:
        """L·∫•y category theo key"""
        if not self.categories:
            return None
        return self.categories.find_one({"key": key})
    
    # ================================================
    # LEGACY METHODS (backward compatibility)
    # ================================================
    
    def store_embedding(self, full_text: str, payload_info: Dict) -> bool:
        """Legacy method - redirect to save_video"""
        video_data = {
            "id": payload_info.get("id") or payload_info.get("video_id"),
            "title": payload_info.get("title"),
            "transcript": full_text,
            "author": {"nickname": payload_info.get("author", {}).get("nickname", "Unknown")},
        }
        video_data.update(payload_info)
        return self.save_video(video_data)
    
    def reset_database(self):
        """Reset t·∫•t c·∫£ data (DANGEROUS!)"""
        print("‚ö†Ô∏è [RESET] Resetting DB...")
        
        if self.videos is not None:
            self.videos.delete_many({})
        if self.search_logs is not None:
            self.search_logs.delete_many({})
        # Kh√¥ng x√≥a users v√† categories
        
        if self.qdrant_client:
            try:
                self.qdrant_client.delete_collection(self.vector_collection)
                self.qdrant_client.create_collection(
                    collection_name=self.vector_collection,
                    vectors_config=VectorParams(size=1024, distance=Distance.COSINE)
                )
            except:
                pass
        
        print("   ‚úÖ Database Cleaned (videos + search_logs).")