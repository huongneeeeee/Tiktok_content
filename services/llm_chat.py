# services/llm_chat.py
"""
TikVault LLM Chat - RAG Answer Generation (OpenAI Version)
"""
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# Cáº¥u hÃ¬nh OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def expand_query(original_query):
    """
    Ká»¹ thuáº­t Query Expansion: Sá»­ dá»¥ng AI Ä‘á»ƒ sinh ra cÃ¡c biáº¿n thá»ƒ tÃ¬m kiáº¿m.
    Káº¿t há»£p: Tá»« Ä‘á»“ng nghÄ©a + Tá»« cá»¥ thá»ƒ hÃ³a + Tá»« liÃªn quan ngá»¯ cáº£nh.
    """
    try:
        prompt = f"""
        ÄÃ³ng vai má»™t chuyÃªn gia tá»‘i Æ°u hÃ³a cÃ´ng cá»¥ tÃ¬m kiáº¿m (SEO) cho ná»n táº£ng Video ngáº¯n.
        Nhiá»‡m vá»¥: Má»Ÿ rá»™ng cÃ¢u truy váº¥n cá»§a ngÆ°á»i dÃ¹ng thÃ nh 3 phiÃªn báº£n khÃ¡c nhau Ä‘á»ƒ tÄƒng kháº£ nÄƒng tÃ¬m kiáº¿m Vector (Semantic Search).
        
        Chiáº¿n lÆ°á»£c má»Ÿ rá»™ng:
        1. Biáº¿n thá»ƒ 1: DÃ¹ng tá»« Ä‘á»“ng nghÄ©a hoáº·c tá»« chuyÃªn mÃ´n chÃ­nh xÃ¡c hÆ¡n.
        2. Biáº¿n thá»ƒ 2: Cá»¥ thá»ƒ hÃ³a cÃ¢u há»i (thÃªm cÃ¡c tá»« nhÆ° "cÃ¡ch lÃ m", "hÆ°á»›ng dáº«n", "review").
        3. Biáº¿n thá»ƒ 3: DÃ¹ng tá»« lÃ³ng, tá»« viáº¿t táº¯t hoáº·c ngÃ´n ngá»¯ nÃ³i thÆ°á»ng gáº·p trÃªn TikTok.

        VÃ Dá»¤ MáºªU (FEW-SHOT):
        Input: "cÃ¡ch lÃ m mÃ³n cuá»‘n"
        Output:
        - cÃ´ng thá»©c lÃ m gá»i cuá»‘n tÃ´m thá»‹t
        - hÆ°á»›ng dáº«n lÃ m bÃ¡nh trÃ¡ng cuá»‘n
        - cÃ¡ch pha nÆ°á»›c cháº¥m mÃ³n cuá»‘n ngon

        Input: "Ä‘i Ä‘Ã  láº¡t máº·c gÃ¬"
        Output:
        - phá»‘i Ä‘á»“ Ä‘i Ä‘Ã  láº¡t cho ná»¯
        - outfit check in Ä‘Ã  láº¡t sá»‘ng áº£o
        - gá»£i Ã½ trang phá»¥c du lá»‹ch mÃ¹a láº¡nh

        Input: "{original_query}"
        Output (Chá»‰ tráº£ vá» 3 dÃ²ng káº¿t quáº£, khÃ´ng giáº£i thÃ­ch gÃ¬ thÃªm):
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=200
        )
        
        # Xá»­ lÃ½ text tráº£ vá» (tÃ¡ch dÃ²ng, xÃ³a gáº¡ch Ä‘áº§u dÃ²ng)
        variations = []
        for line in response.choices[0].message.content.split('\n'):
            clean_line = line.strip().replace('- ', '').replace('* ', '')
            if clean_line:
                variations.append(clean_line)
        
        # LuÃ´n luÃ´n thÃªm cÃ¢u gá»‘c vÃ o danh sÃ¡ch
        variations.append(original_query)
        
        # Lá»c trÃ¹ng láº·p vÃ  láº¥y tá»‘i Ä‘a 4 cÃ¢u
        return list(set(variations))

    except Exception as e:
        print(f"âš ï¸ Lá»—i Expand Query: {e}")
        return [original_query]


def generate_rag_answer(user_query, search_results, conversation_history=None):
    """
    Generate detailed AI answer using RAG with full transcript context (OpenAI Version)
    Supports multi-turn conversation with optional history.
    """
    if not search_results:
        return "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y video nÃ o liÃªn quan Ä‘áº¿n cÃ¢u há»i cá»§a báº¡n."

    # Build comprehensive context from search results
    context_parts = []
    
    for idx, item in enumerate(search_results):
        video_num = idx + 1
        title = item.get('title', 'KhÃ´ng cÃ³ tiÃªu Ä‘á»')
        
        # Author info
        author = item.get('author', {})
        author_name = author.get('nickname', 'Unknown') if isinstance(author, dict) else str(author)
        
        # Full transcript
        transcript = item.get('transcript', '')
        if transcript and len(transcript) > 500:
            transcript = transcript[:1500]
        
        # AI analysis data - Support both old and new format
        ai_analysis = item.get('ai_analysis', {})
        
        # Try new Knowledge Card format first
        knowledge_card = ai_analysis.get('knowledge_card', {})
        if knowledge_card:
            ai_summary = knowledge_card.get('summary', '')
            key_takeaways = knowledge_card.get('key_takeaways', [])
            action_items = knowledge_card.get('action_items', [])
            entities = knowledge_card.get('entities', {})
            
            structured_info = ""
            if key_takeaways:
                structured_info += f"\n   â€¢ Äiá»ƒm chÃ­nh: {'; '.join(key_takeaways)}"
            if action_items:
                structured_info += f"\n   â€¢ CÃ¡c bÆ°á»›c: {'; '.join(action_items[:5])}"
            if entities.get('ingredients'):
                structured_info += f"\n   â€¢ NguyÃªn liá»‡u: {', '.join(entities['ingredients'])}"
            if entities.get('products'):
                structured_info += f"\n   â€¢ Sáº£n pháº©m: {', '.join(entities['products'])}"
            if entities.get('locations'):
                structured_info += f"\n   â€¢ Äá»‹a Ä‘iá»ƒm: {', '.join(entities['locations'])}"
        else:
            # Fallback to old format
            ai_summary = ai_analysis.get('summary', '') or ai_analysis.get('meta', {}).get('summary', '')
            rag_data = ai_analysis.get('rag_data', {})
            
            structured_info = ""
            if rag_data:
                if rag_data.get('ingredients'):
                    structured_info += f"\n   â€¢ NguyÃªn liá»‡u: {', '.join(rag_data['ingredients'])}"
                if rag_data.get('steps'):
                    structured_info += f"\n   â€¢ CÃ¡c bÆ°á»›c: {'; '.join(rag_data['steps'][:5])}"
                if rag_data.get('products'):
                    structured_info += f"\n   â€¢ Sáº£n pháº©m: {', '.join(rag_data['products'])}"
                if rag_data.get('locations'):
                    structured_info += f"\n   â€¢ Äá»‹a Ä‘iá»ƒm: {', '.join(rag_data['locations'])}"
                if rag_data.get('tips'):
                    structured_info += f"\n   â€¢ Máº¹o hay: {', '.join(rag_data['tips'])}"
        
        # Classification
        classification = ai_analysis.get('classification', {})
        category = classification.get('category_path', '') or classification.get('level_1', '')
        
        context_parts.append(f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¹ VIDEO {video_num}: {title}
ğŸ‘¤ TÃ¡c giáº£: @{author_name}
ğŸ“‚ Danh má»¥c: {category}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ¤– TÃ“M Táº®T AI: {ai_summary}
{f"ğŸ“‹ THÃ”NG TIN CHI TIáº¾T:{structured_info}" if structured_info else ""}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ Ná»˜I DUNG Äáº¦Y Äá»¦ (TRANSCRIPT):
{transcript if transcript else "[KhÃ´ng cÃ³ transcript]"}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    full_context = "\n".join(context_parts)

    system_prompt = """Báº¡n lÃ  TikVault AI Assistant - chuyÃªn gia phÃ¢n tÃ­ch ná»™i dung video TikTok.
Nhiá»‡m vá»¥: Tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn Dá»® LIá»†U VIDEO má»™t cÃ¡ch CHI TIáº¾T vÃ  Cá»¤ THá»‚.

NguyÃªn táº¯c:
1. Äá»ŒC Ká»¸ TRANSCRIPT - ÄÃ¢y lÃ  nguá»“n thÃ´ng tin chÃ­nh xÃ¡c nháº¥t
2. TRÃCH DáºªN NGUá»’N - Ghi [Video 1], [Video 2] khi láº¥y thÃ´ng tin
3. Cá»¤ THá»‚ VÃ€ CHI TIáº¾T - ÄÆ°a ra sá»‘ liá»‡u, tÃªn gá»i, bÆ°á»›c lÃ m cá»¥ thá»ƒ
4. KHÃ”NG bá»‹a thÃ´ng tin - Chá»‰ dá»±a vÃ o dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p
5. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n, dá»… hiá»ƒu"""

    user_prompt = f"""# CÃ‚U Há»I
"{user_query}"

# Dá»® LIá»†U VIDEO THAM KHáº¢O
{full_context}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn dá»¯ liá»‡u video trÃªn."""

    try:
        # Build messages with conversation history
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history if provided
        if conversation_history:
            for msg in conversation_history[-6:]:  # Keep last 6 messages (3 turns)
                messages.append({
                    "role": msg.get("role", "user"),
                    "content": msg.get("content", "")
                })
        
        # Add current user query with context
        messages.append({"role": "user", "content": user_prompt})
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.3,
            max_tokens=2500
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ Lá»—i OpenAI RAG: {e}")
        import traceback
        traceback.print_exc()
        return "Xin lá»—i, há»‡ thá»‘ng AI Ä‘ang báº­n. Vui lÃ²ng thá»­ láº¡i sau."


# ============================================================
# PHASE 3: PLANNER AGENT
# ============================================================

PLANNING_KEYWORDS = [
    "lÃªn káº¿ hoáº¡ch", "plan ", "lá»‹ch trÃ¬nh", "hÃ nh trÃ¬nh", "gá»£i Ã½ lá»‹ch",
    "itinerary", "ngÃ y 1", "ngÃ y 2", "Ä‘i chÆ¡i", "du lá»‹ch", "trip",
    "á»Ÿ Ä‘Ã¢u Äƒn gÃ¬", "2 ngÃ y", "3 ngÃ y", "cuá»‘i tuáº§n", "weekend",
    "Ä‘á»‹a Ä‘iá»ƒm", "quÃ¡n Äƒn", "checklist", "káº¿ hoáº¡ch"
]


def detect_planning_intent(query):
    """
    Detect if the query is asking for a plan/itinerary.
    Returns True if planning mode should be activated.
    """
    query_lower = query.lower()
    for keyword in PLANNING_KEYWORDS:
        if keyword in query_lower:
            return True
    return False


def generate_travel_plan(user_query, search_results, conversation_history=None):
    """
    Planner Agent: Synthesize multiple videos into a structured travel/activity plan.
    """
    if not search_results:
        return "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin trong thÆ° viá»‡n video Ä‘á»ƒ láº­p káº¿ hoáº¡ch."

    # Build comprehensive video data
    video_data = []
    for idx, item in enumerate(search_results):
        ai_analysis = item.get('ai_analysis', {})
        knowledge_card = ai_analysis.get('knowledge_card', {})
        classification = ai_analysis.get('classification', {})
        
        video_info = {
            "video_num": idx + 1,
            "title": knowledge_card.get('title') or item.get('title', 'Untitled'),
            "category": classification.get('category_path', 'N/A'),
            "summary": knowledge_card.get('summary', ai_analysis.get('summary', '')),
            "locations": knowledge_card.get('entities', {}).get('locations', []),
            "ingredients": knowledge_card.get('entities', {}).get('ingredients', []),
            "products": knowledge_card.get('entities', {}).get('products', []),
            "key_takeaways": knowledge_card.get('key_takeaways', []),
            "action_items": knowledge_card.get('action_items', []),
            "tags": knowledge_card.get('tags', [])
        }
        video_data.append(video_info)

    # Format video context for planner
    video_context = ""
    for v in video_data:
        video_context += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¹ VIDEO {v['video_num']}: {v['title']}
ğŸ“‚ Danh má»¥c: {v['category']}
ğŸ“ TÃ³m táº¯t: {v['summary']}
ğŸ“ Äá»‹a Ä‘iá»ƒm: {', '.join(v['locations']) if v['locations'] else 'N/A'}
ğŸ’¡ Highlights: {', '.join(v['key_takeaways'][:3]) if v['key_takeaways'] else 'N/A'}
ğŸ·ï¸ Tags: {', '.join(v['tags']) if v['tags'] else 'N/A'}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

    system_prompt = """Báº¡n lÃ  TikVault Travel Planner - chuyÃªn gia láº­p káº¿ hoáº¡ch du lá»‹ch vÃ  tráº£i nghiá»‡m.
Nhiá»‡m vá»¥: Tá»•ng há»£p thÃ´ng tin tá»« nhiá»u video TikTok Ä‘á»ƒ táº¡o ra Káº¾ HOáº CH Cá»¤ THá»‚.

NGUYÃŠN Táº®C Láº¬P Káº¾ HOáº CH:
1. Sáº¯p xáº¿p theo THá»œI GIAN há»£p lÃ½ (sÃ¡ng â†’ trÆ°a â†’ chiá»u â†’ tá»‘i)
2. Ghi RÃ• nguá»“n video cho má»—i gá»£i Ã½: [Video X]
3. Æ¯á»›c tÃ­nh THá»œI GIAN vÃ  CHI PHÃ náº¿u cÃ³ thÃ´ng tin
4. ThÃªm TIPS tá»« cÃ¡c video vÃ o káº¿ hoáº¡ch

FORMAT OUTPUT:
ğŸ“… **NGÃ€Y 1: [Chá»§ Ä‘á»]**

ğŸŒ… **SÃ¡ng:**
- [Hoáº¡t Ä‘á»™ng 1] [Video X]
- [Hoáº¡t Ä‘á»™ng 2] [Video Y]

ğŸŒ **TrÆ°a:**
- [Äá»‹a Ä‘iá»ƒm Äƒn trÆ°a] [Video Z]

ğŸŒ† **Chiá»u - Tá»‘i:**
- [Hoáº¡t Ä‘á»™ng] [Video X]

ğŸ’¡ **Tips:**
- [Máº¹o tá»« video]

ğŸ“… **NGÃ€Y 2: [Chá»§ Ä‘á»]**
...

ğŸ’° **Æ¯á»›c tÃ­nh chi phÃ­:** [náº¿u cÃ³]
âš ï¸ **LÆ°u Ã½:** [nhá»¯ng Ä‘iá»u cáº§n chÃº Ã½]"""

    user_prompt = f"""# YÃŠU Cáº¦U Láº¬P Káº¾ HOáº CH
"{user_query}"

# Dá»® LIá»†U Tá»ª CÃC VIDEO ÄÃƒ LÆ¯U
{video_context}

HÃ£y tá»•ng há»£p thÃ´ng tin tá»« cÃ¡c video trÃªn vÃ  táº¡o káº¿ hoáº¡ch chi tiáº¿t.
Nhá»› ghi [Video X] sau má»—i gá»£i Ã½ Ä‘á»ƒ ngÆ°á»i dÃ¹ng biáº¿t nguá»“n."""

    try:
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history
        if conversation_history:
            for msg in conversation_history[-4:]:
                messages.append({
                    "role": msg.get("role", "user"),
                    "content": msg.get("content", "")
                })
        
        messages.append({"role": "user", "content": user_prompt})
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.4,
            max_tokens=3000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ Lá»—i Planner: {e}")
        import traceback
        traceback.print_exc()
        return "Xin lá»—i, khÃ´ng thá»ƒ táº¡o káº¿ hoáº¡ch lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i."


def generate_comparison(user_query, videos, conversation_history=None):
    """
    Generate comparison analysis between multiple videos.
    Used when user selects multiple videos and clicks Compare.
    """
    if len(videos) < 2:
        return "Cáº§n Ã­t nháº¥t 2 video Ä‘á»ƒ so sÃ¡nh."
    
    # Build context for each video
    video_summaries = []
    for idx, video in enumerate(videos):
        num = idx + 1
        title = video.get('title', 'KhÃ´ng cÃ³ tiÃªu Ä‘á»')
        
        # Get transcript for deep comparison
        transcript = video.get('transcript', '')
        if transcript and len(transcript) > 2000:
            transcript = transcript[:2000] + "...(Ä‘Ã£ cáº¯t bá»›t)"
        elif not transcript:
            transcript = "[KhÃ´ng cÃ³ transcript]"

        ai_analysis = video.get('ai_analysis', {})
        knowledge_card = ai_analysis.get('knowledge_card', {})
        
        summary = knowledge_card.get('summary', ai_analysis.get('summary', ''))
        category_path = knowledge_card.get('category_path', 
                         ai_analysis.get('classification', {}).get('category_path', 'ChÆ°a phÃ¢n loáº¡i'))
        key_takeaways = knowledge_card.get('key_takeaways', [])
        action_items = knowledge_card.get('action_items', [])
        
        entities = knowledge_card.get('entities', {})
        ingredients = entities.get('ingredients', [])
        locations = entities.get('locations', [])
        products = entities.get('products', [])
        
        video_info = f"""
### Video {num}: {title}
- **Danh má»¥c:** {category_path}
- **TÃ³m táº¯t:** {summary}
- **Äiá»ƒm chÃ­nh:** {', '.join(map(str, key_takeaways)) if key_takeaways else 'KhÃ´ng cÃ³'}
- **CÃ¡c bÆ°á»›c:** {', '.join(map(str, action_items)) if action_items else 'KhÃ´ng cÃ³'}

#### Chi tiáº¿t Entities:
{f"- NguyÃªn liá»‡u: {', '.join(map(str, ingredients))}" if ingredients else ""}
{f"- Äá»‹a Ä‘iá»ƒm: {', '.join(map(str, locations))}" if locations else ""}
{f"- Sáº£n pháº©m: {', '.join(map(str, products))}" if products else ""}

#### Transcript (TrÃ­ch Ä‘oáº¡n):
{transcript}
--------------------------------------------------
"""
        video_summaries.append(video_info)
    
    videos_context = "\n".join(video_summaries)
    
    system_prompt = """Báº¡n lÃ  TikVault Expert - chuyÃªn gia phÃ¢n tÃ­ch vÃ  so sÃ¡nh ná»™i dung video.
Nhiá»‡m vá»¥: So sÃ¡nh cÃ¡c video Ä‘Æ°á»£c cung cáº¥p vÃ  Ä‘Æ°a ra phÃ¢n tÃ­ch chi tiáº¿t, sÃ¢u sáº¯c.

Cáº¥u trÃºc tráº£ lá»i:
1. **Tá»•ng quan:** NÃªu ngáº¯n gá»n chá»§ Ä‘á» chung cá»§a cÃ¡c video.
2. **So sÃ¡nh chi tiáº¿t:** (Táº¡o báº£ng hoáº·c danh sÃ¡ch so sÃ¡nh)
   - **Vá» Ná»™i dung/PhÆ°Æ¡ng phÃ¡p:** CÃ¡ch lÃ m khÃ¡c nhau tháº¿ nÃ o? NguyÃªn liá»‡u/CÃ´ng cá»¥ khÃ¡c nhau ra sao?
   - **Vá» Phong cÃ¡ch:** Tone giá»ng, cÃ¡ch truyá»n Ä‘áº¡t, Ä‘á»™ chi tiáº¿t.
   - **Vá» ThÃ´ng tin:** Video nÃ o cÃ³ thÃ´ng tin Ä‘á»™c Ä‘Ã¡o mÃ  video kia khÃ´ng cÃ³?
3. **Æ¯u Ä‘iá»ƒm & NhÆ°á»£c Ä‘iá»ƒm:** PhÃ¢n tÃ­ch Ä‘iá»ƒm máº¡nh/yáº¿u cá»§a tá»«ng video.
4. **Káº¿t luáº­n & Äá» xuáº¥t:** 
   - [Video X] phÃ¹ há»£p cho ai/trÆ°á»ng há»£p nÃ o?
   - [Video Y] phÃ¹ há»£p cho ai/trÆ°á»ng há»£p nÃ o?

Sá»­ dá»¥ng [Video X] Ä‘á»ƒ chá»‰ rÃµ nguá»“n.
HÃ£y phÃ¢n tÃ­ch SÃ‚U dá»±a trÃªn transcript vÃ  cÃ¡c bÆ°á»›c thá»±c hiá»‡n cá»¥ thá»ƒ, khÃ´ng chá»‰ nÃ³i chung chung."""

    user_prompt = f"""# YÃŠU Cáº¦U SO SÃNH
"{user_query}"

# Dá»® LIá»†U CÃC VIDEO
{videos_context}

HÃ£y phÃ¢n tÃ­ch vÃ  so sÃ¡nh cÃ¡c video trÃªn má»™t cÃ¡ch chi tiáº¿t nháº¥t cÃ³ thá»ƒ."""

    try:
        messages = [{"role": "system", "content": system_prompt}]
        
        if conversation_history:
            for msg in conversation_history[-4:]:
                messages.append({
                    "role": msg.get("role", "user"),
                    "content": msg.get("content", "")
                })
        
        messages.append({"role": "user", "content": user_prompt})
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.4,
            max_tokens=2000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ Lá»—i Compare: {e}")
        import traceback
        traceback.print_exc()
        return "Xin lá»—i, khÃ´ng thá»ƒ so sÃ¡nh video lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i."