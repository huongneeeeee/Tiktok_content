# services/reasoning_checker.py
"""
Phase 3 - Step 3.7: Reasoning Readiness Check

Features:
- Kiá»ƒm tra ná»™i dung cÃ³ Ä‘á»§ rÃµ Ä‘á»ƒ AI suy luáº­n khÃ´ng
- GÃ¡n flag reasoning_ready = True/False
- ÄÃ¡nh giÃ¡ content_quality tá»•ng thá»ƒ
- Äá» xuáº¥t hÃ nh Ä‘á»™ng náº¿u chÆ°a sáºµn sÃ ng
"""

from typing import Dict, List, Optional


# ============================================================
# REASONING CRITERIA
# ============================================================

# Minimum thresholds
MIN_WORD_COUNT = 5          # Tá»‘i thiá»ƒu 5 tá»« cÃ³ nghÄ©a
MIN_CHUNK_WITH_CONTENT = 1  # Ãt nháº¥t 1 chunk cÃ³ ná»™i dung
MIN_CONTENT_DENSITY = 0.3   # 30% chunks pháº£i cÃ³ content


def assess_content_completeness(content_chunks: List[Dict]) -> Dict:
    """
    ÄÃ¡nh giÃ¡ Ä‘á»™ Ä‘áº§y Ä‘á»§ cá»§a ná»™i dung.
    
    Returns:
    {
        "is_complete": bool,
        "word_count": int,
        "chunks_with_content": int,
        "content_density": float,
        "issues": [...]
    }
    """
    if not content_chunks:
        return {
            "is_complete": False,
            "word_count": 0,
            "chunks_with_content": 0,
            "content_density": 0.0,
            "issues": ["no_chunks"]
        }
    
    issues = []
    
    # Count words across all chunks
    total_words = 0
    chunks_with_content = 0
    
    for chunk in content_chunks:
        final_text = chunk.get("final_text", "") or chunk.get("cleaned_text", "")
        if final_text:
            words = len(final_text.split())
            total_words += words
            if words >= 3:  # At least 3 words to count as "has content"
                chunks_with_content += 1
    
    content_density = chunks_with_content / len(content_chunks) if content_chunks else 0
    
    # Check minimums
    if total_words < MIN_WORD_COUNT:
        issues.append("too_few_words")
    
    if chunks_with_content < MIN_CHUNK_WITH_CONTENT:
        issues.append("no_chunks_with_content")
    
    if content_density < MIN_CONTENT_DENSITY:
        issues.append("low_content_density")
    
    is_complete = len(issues) == 0
    
    return {
        "is_complete": is_complete,
        "word_count": total_words,
        "chunks_with_content": chunks_with_content,
        "total_chunks": len(content_chunks),
        "content_density": round(content_density, 2),
        "issues": issues
    }


def assess_content_coherence(content_chunks: List[Dict]) -> Dict:
    """
    ÄÃ¡nh giÃ¡ tÃ­nh máº¡ch láº¡c cá»§a ná»™i dung.
    
    Returns:
    {
        "is_coherent": bool,
        "has_structure": bool,
        "confidence_distribution": dict,
        "issues": [...]
    }
    """
    if not content_chunks:
        return {
            "is_coherent": False,
            "has_structure": False,
            "confidence_distribution": {},
            "issues": ["no_chunks"]
        }
    
    issues = []
    
    # Check content confidence distribution
    confidence_counts = {"high": 0, "medium": 0, "low": 0}
    
    for chunk in content_chunks:
        conf = chunk.get("content_confidence", "low")
        confidence_counts[conf] = confidence_counts.get(conf, 0) + 1
    
    # Check if mostly low confidence
    total = len(content_chunks)
    low_ratio = confidence_counts.get("low", 0) / total if total > 0 else 1.0
    
    if low_ratio > 0.8:
        issues.append("mostly_low_confidence")
    
    # Check for structure (multiple scenes with content)
    has_structure = len(content_chunks) > 1 and confidence_counts.get("high", 0) + confidence_counts.get("medium", 0) > 0
    
    if not has_structure:
        issues.append("no_clear_structure")
    
    is_coherent = len(issues) == 0
    
    return {
        "is_coherent": is_coherent,
        "has_structure": has_structure,
        "confidence_distribution": confidence_counts,
        "low_confidence_ratio": round(low_ratio, 2),
        "issues": issues
    }


def assess_reasoning_potential(content_chunks: List[Dict]) -> Dict:
    """
    ÄÃ¡nh giÃ¡ kháº£ nÄƒng AI cÃ³ thá»ƒ suy luáº­n tá»« ná»™i dung.
    
    Checks:
    - Can we understand the topic?
    - Is there enough context?
    - Are there actionable insights?
    """
    if not content_chunks:
        return {
            "can_reason": False,
            "topic_clarity": "none",
            "context_level": "none",
            "issues": ["no_content"]
        }
    
    issues = []
    
    # Collect all text
    all_text = ""
    for chunk in content_chunks:
        text = chunk.get("final_text", "") or chunk.get("cleaned_text", "")
        if text:
            all_text += " " + text
    
    all_text = all_text.strip()
    word_count = len(all_text.split())
    
    # Topic clarity
    if word_count >= 20:
        topic_clarity = "clear"
    elif word_count >= 10:
        topic_clarity = "partial"
    elif word_count >= 5:
        topic_clarity = "vague"
    else:
        topic_clarity = "none"
        issues.append("topic_unclear")
    
    # Context level
    chunks_with_context = sum(1 for c in content_chunks 
                             if len((c.get("final_text", "") or "").split()) >= 5)
    
    if chunks_with_context >= 3:
        context_level = "rich"
    elif chunks_with_context >= 2:
        context_level = "adequate"
    elif chunks_with_context >= 1:
        context_level = "minimal"
    else:
        context_level = "none"
        issues.append("no_context")
    
    can_reason = topic_clarity in ["clear", "partial"] and context_level in ["rich", "adequate", "minimal"]
    
    return {
        "can_reason": can_reason,
        "topic_clarity": topic_clarity,
        "context_level": context_level,
        "total_words": word_count,
        "issues": issues
    }


# ============================================================
# MAIN CHECK
# ============================================================

def check_reasoning_ready(content_chunks: List[Dict], quality_data: Dict = None) -> Dict:
    """
    Kiá»ƒm tra tá»•ng há»£p: ná»™i dung cÃ³ Ä‘á»§ rÃµ Ä‘á»ƒ AI suy luáº­n khÃ´ng?
    
    Args:
        content_chunks: Processed chunks from content pipeline
        quality_data: Quality info from Phase 2 (stt_quality, ocr_quality, data_status)
    
    Returns:
    {
        "reasoning_ready": True | False,
        "reason": str,
        "content_quality": "high" | "medium" | "low",
        "assessments": {
            "completeness": {...},
            "coherence": {...},
            "reasoning_potential": {...}
        },
        "recommended_actions": [...]
    }
    """
    if quality_data is None:
        quality_data = {}
    
    # Run all assessments
    completeness = assess_content_completeness(content_chunks)
    coherence = assess_content_coherence(content_chunks)
    reasoning = assess_reasoning_potential(content_chunks)
    
    # Collect all issues
    all_issues = (
        completeness.get("issues", []) +
        coherence.get("issues", []) +
        reasoning.get("issues", [])
    )
    
    # Check data_status from Phase 2
    data_status = quality_data.get("data_status", "valid")
    
    # Decision logic
    reasoning_ready = True
    reasons = []
    
    # Critical failures
    if not completeness["is_complete"]:
        reasoning_ready = False
        reasons.append("Content khÃ´ng Ä‘á»§ Ä‘áº§y Ä‘á»§")
    
    if not reasoning["can_reason"]:
        reasoning_ready = False
        reasons.append("KhÃ´ng Ä‘á»§ context Ä‘á»ƒ suy luáº­n")
    
    # Soft failures (warning but may proceed)
    if data_status == "weak" and not completeness["is_complete"]:
        reasoning_ready = False
        reasons.append("Dá»¯ liá»‡u yáº¿u tá»« Phase 2")
    
    # Content quality
    issue_count = len(all_issues)
    
    if issue_count == 0:
        content_quality = "high"
    elif issue_count <= 2:
        content_quality = "medium"
    else:
        content_quality = "low"
    
    # Generate reason string
    if reasoning_ready:
        reason = "Ná»™i dung Ä‘á»§ rÃµ rÃ ng vÃ  cÃ³ cáº¥u trÃºc Ä‘á»ƒ AI suy luáº­n"
    else:
        reason = "; ".join(reasons) if reasons else "Ná»™i dung khÃ´ng Ä‘á»§ Ä‘iá»u kiá»‡n"
    
    # Recommended actions
    recommended_actions = []
    
    if not reasoning_ready:
        if "too_few_words" in all_issues:
            recommended_actions.append("Giá»¯ nguyÃªn ná»™i dung, khÃ´ng Ã©p phÃ¢n loáº¡i")
        if "topic_unclear" in all_issues:
            recommended_actions.append("Chá»‰ sá»­ dá»¥ng metadata Ä‘á»ƒ phÃ¢n loáº¡i")
        if "mostly_low_confidence" in all_issues:
            recommended_actions.append("ÄÃ¡nh dáº¥u low-confidence, háº¡n cháº¿ suy luáº­n")
    
    if not recommended_actions:
        if reasoning_ready:
            recommended_actions.append("Tiáº¿p tá»¥c Phase tiáº¿p theo (classification, scripting)")
        else:
            recommended_actions.append("Giá»¯ metadata vÃ  scene structure, bá» qua deep analysis")
    
    print(f"   ðŸ“Š [REASONING] Ready: {reasoning_ready}")
    print(f"   ðŸ“Š [REASONING] Quality: {content_quality}")
    if all_issues:
        print(f"   âš ï¸ [REASONING] Issues: {', '.join(all_issues[:5])}")
    
    return {
        "reasoning_ready": reasoning_ready,
        "reason": reason,
        "content_quality": content_quality,
        "assessments": {
            "completeness": completeness,
            "coherence": coherence,
            "reasoning_potential": reasoning
        },
        "all_issues": all_issues,
        "recommended_actions": recommended_actions
    }


# ============================================================
# TEST
# ============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ðŸ§ª Reasoning Checker Test")
    print("=" * 60)
    
    # Test case 1: Good content
    print("\nðŸ“ Test 1: Good content")
    good_chunks = [
        {"final_text": "HÃ´m nay mÃ¬nh sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n lÃ m bÃ¡nh.", "content_confidence": "high"},
        {"final_text": "BÆ°á»›c 1 lÃ  chuáº©n bá»‹ nguyÃªn liá»‡u gá»“m bá»™t vÃ  trá»©ng.", "content_confidence": "high"},
        {"final_text": "BÆ°á»›c 2 lÃ  trá»™n Ä‘á»u vÃ  nÆ°á»›ng trong 30 phÃºt.", "content_confidence": "medium"},
    ]
    
    result1 = check_reasoning_ready(good_chunks, {"data_status": "valid"})
    print(f"   Ready: {result1['reasoning_ready']}")
    print(f"   Quality: {result1['content_quality']}")
    
    # Test case 2: Poor content
    print("\nðŸ“ Test 2: Poor content")
    poor_chunks = [
        {"final_text": "Hi", "content_confidence": "low"},
        {"final_text": "", "content_confidence": "low"},
    ]
    
    result2 = check_reasoning_ready(poor_chunks, {"data_status": "weak"})
    print(f"   Ready: {result2['reasoning_ready']}")
    print(f"   Quality: {result2['content_quality']}")
    print(f"   Reason: {result2['reason']}")
    
    # Test case 3: Mixed
    print("\nðŸ“ Test 3: Mixed content")
    mixed_chunks = [
        {"final_text": "Má»™t video vá» náº¥u Äƒn Ä‘Æ¡n giáº£n.", "content_confidence": "medium"},
        {"final_text": "", "content_confidence": "low"},
    ]
    
    result3 = check_reasoning_ready(mixed_chunks, {"data_status": "valid"})
    print(f"   Ready: {result3['reasoning_ready']}")
    print(f"   Quality: {result3['content_quality']}")
