# backend/app/services/analysis/gemini_video_analyzer.py
"""
Gemini Video Analyzer Service

PhÃ¢n tÃ­ch video sá»­ dá»¥ng Gemini API vá»›i structured JSON output.
TÃ­ch há»£p LangChain JsonOutputParser Ä‘á»ƒ Ä‘áº£m báº£o output Ä‘Ãºng format.

Features:
- Upload video lÃªn Gemini File API
- Prompt chi tiáº¿t cho phÃ¢n tÃ­ch video
- Parse response thÃ nh Pydantic model
- Xá»­ lÃ½ lá»—i vÃ  retry logic
"""

import os
import sys
import time
import json
import re
from typing import Dict, Optional
from datetime import datetime

# Ensure backend is in path
BACKEND_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
if BACKEND_DIR not in sys.path:
    sys.path.insert(0, BACKEND_DIR)

from app.core.config import Config
from app.models.video_analysis_models import VideoAnalysisResult
from app.services.ingest.gemini_uploader import GeminiFileUploader, GeminiUploadError

# Import Google GenAI SDK
try:
    from google import genai
    from google.genai import types
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("âš ï¸ [GEMINI_ANALYZER] google-genai SDK not installed")

# Import LangChain for JsonOutputParser
try:
    from langchain_core.output_parsers import JsonOutputParser
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("âš ï¸ [GEMINI_ANALYZER] langchain not installed")


# ============================================================
# PROMPT TEMPLATE
# ============================================================


SYSTEM_INSTRUCTION = """Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch ná»™i dung video TikTok/short-form video chuyÃªn nghiá»‡p.
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  xem video vÃ  phÃ¢n tÃ­ch chi tiáº¿t cÃ¡c yáº¿u tá»‘ ká»¹ thuáº­t, ná»™i dung, vÃ  tiá»m nÄƒng viral.
Báº¡n cÃ³ kiáº¿n thá»©c sÃ¢u rá»™ng vá» quay dá»±ng, Ã¡nh sÃ¡ng, Ã¢m thanh, vÃ  tÃ¢m lÃ½ ngÆ°á»i xem TikTok."""

ANALYSIS_PROMPT_TEMPLATE = """HÃ£y phÃ¢n tÃ­ch video nÃ y theo cÃ¡c tiÃªu chÃ­ sau vÃ  tráº£ vá» káº¿t quáº£ JSON.

## 1. THÃ”NG TIN CHUNG (general_info)
- **title**: Äáº·t tiÃªu Ä‘á» phÃ¹ há»£p cho video dá»±a trÃªn ná»™i dung
- **category**: PhÃ¢n loáº¡i video (Vlog, Tutorial, Review, Drama, Ads, Entertainment, Education, Comedy, Lifestyle, etc.)
- **overall_sentiment**: Cáº£m xÃºc chá»§ Ä‘áº¡o (HÃ i hÆ°á»›c, NghiÃªm tÃºc, Cáº£m Ä‘á»™ng, Gay cáº¥n, Vui váº», Buá»“n, KÃ­ch thÃ­ch, etc.)
- **target_audience**: MÃ´ táº£ chÃ¢n dung khÃ¡n giáº£ má»¥c tiÃªu (Ä‘á»™ tuá»•i, sá»Ÿ thÃ­ch, hÃ nh vi)

## 2. PHÃ‚N TÃCH Ná»˜I DUNG (content_analysis)
- **main_objective**: Má»¥c tiÃªu chÃ­nh cá»§a video (BÃ¡n hÃ ng, Branding, GiÃ¡o dá»¥c, Giáº£i trÃ­, Chia sáº» kinh nghiá»‡m, etc.)
- **key_message**: ThÃ´ng Ä‘iá»‡p cá»‘t lÃµi mÃ  video muá»‘n truyá»n táº£i
- **hook_strategy**: CÃ¡ch video giá»¯ chÃ¢n ngÆ°á»i xem trong 3-5 giÃ¢y Ä‘áº§u tiÃªn

## 3. PHÃ‚N TÃCH Ká»ŠCH Báº¢N (script_breakdown)
Chia video thÃ nh cÃ¡c Ä‘oáº¡n/scene rÃµ rÃ ng. Vá»›i Má»–I ÄOáº N, xÃ¡c Ä‘á»‹nh:
- **segment_id**: Sá»‘ thá»© tá»± (1, 2, 3...)
- **time_range**: Khoáº£ng thá»i gian (format: "00:00 - 00:15")
- **start_seconds**: GiÃ¢y báº¯t Ä‘áº§u (sá»‘)
- **end_seconds**: GiÃ¢y káº¿t thÃºc (sá»‘)
- **visual_description**: MÃ´ táº£ chi tiáº¿t cáº£nh quay (ngÆ°á»i, váº­t, hÃ nh Ä‘á»™ng, bá»‘i cáº£nh, mÃ u sáº¯c)
- **camera_angle**: GÃ³c mÃ¡y (ToÃ n cáº£nh, Trung cáº£nh, Cáº­n cáº£nh, POV, Aerial, Tracking, etc.)
- **audio_transcript**: Lá»i thoáº¡i hoáº·c mÃ´ táº£ Ã¢m thanh. Náº¿u lÃ  nháº¡c, ghi rÃµ thá»ƒ loáº¡i vÃ  mood
- **on_screen_text**: Text xuáº¥t hiá»‡n trÃªn mÃ n hÃ¬nh (caption, subtitle, overlay)
- **pacing**: Nhá»‹p Ä‘á»™ (Nhanh, Cháº­m, Dá»“n dáº­p, Vá»«a pháº£i, TÄ©nh láº·ng)

## 4. ÄÃNH GIÃ Ká»¸ THUáº¬T (technical_audit)
- **editing_style**: Phong cÃ¡ch edit (Jump cuts, MÆ°á»£t mÃ , Minimalist, Cinematic, Raw, Trend TikTok, etc.)
- **sound_design**: ÄÃ¡nh giÃ¡ Ã¢m thanh/nháº¡c ná»n (cháº¥t lÆ°á»£ng, phÃ¹ há»£p, mixing)
- **cta_analysis**: PhÃ¢n tÃ­ch Call to Action (cÃ³ khÃ´ng, vá»‹ trÃ­, hiá»‡u quáº£)
- **video_quality**: Cháº¥t lÆ°á»£ng hÃ¬nh áº£nh (Ä‘á»™ phÃ¢n giáº£i, Ã¡nh sÃ¡ng, mÃ u sáº¯c)
- **transitions**: CÃ¡c hiá»‡u á»©ng chuyá»ƒn cáº£nh

## 5. TIá»€M NÄ‚NG VIRAL (virality_factors)
- **score**: Äiá»ƒm tá»« 1-10 (10 lÃ  tiá»m nÄƒng cao nháº¥t)
- **reasons**: Giáº£i thÃ­ch táº¡i sao video cÃ³/khÃ´ng cÃ³ tiá»m nÄƒng viral
- **improvement_suggestions**: Äá» xuáº¥t cá»¥ thá»ƒ Ä‘á»ƒ cáº£i thiá»‡n video
- **strengths**: Danh sÃ¡ch Ä‘iá»ƒm máº¡nh cá»§a video
- **weaknesses**: Danh sÃ¡ch Ä‘iá»ƒm yáº¿u cáº§n cáº£i thiá»‡n

---

âš ï¸ QUAN TRá»ŒNG: Tráº£ vá» káº¿t quáº£ DÆ¯á»šI Dáº NG JSON há»£p lá»‡ theo schema sau:

{format_instructions}

Chá»‰ tráº£ vá» JSON, khÃ´ng cÃ³ text giáº£i thÃ­ch thÃªm trÆ°á»›c hoáº·c sau JSON."""


# ============================================================
# GEMINI VIDEO ANALYZER
# ============================================================

class GeminiVideoAnalyzer:
    """
    PhÃ¢n tÃ­ch video sá»­ dá»¥ng Gemini API.
    
    Usage:
        analyzer = GeminiVideoAnalyzer()
        result = analyzer.analyze_video("path/to/video.mp4")
        
        if result["success"]:
            analysis = result["analysis"]  # VideoAnalysisResult
    """
    
    def __init__(self, api_key: str = None, model_name: str = "gemini-2.5-flash"):
        """
        Khá»Ÿi táº¡o Gemini Video Analyzer.
        
        Args:
            api_key: Optional API key. Láº¥y tá»« Config náº¿u khÃ´ng cung cáº¥p.
            model_name: Gemini model Ä‘á»ƒ sá»­ dá»¥ng
        """
        if not GENAI_AVAILABLE:
            raise ImportError("google-genai SDK not installed. Run: pip install google-genai")
        
        if not LANGCHAIN_AVAILABLE:
            raise ImportError("langchain not installed. Run: pip install langchain langchain-core")
        
        self.api_key = api_key or Config.GEMINI_API_KEY
        
        # Fallback: Try loading .env again if key is missing
        if not self.api_key:
            try:
                from dotenv import load_dotenv
                print("âš ï¸ [GEMINI_ANALYZER] API Key not found in Config, attempting manual .env load...")
                load_dotenv(override=True)
                self.api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
            except Exception as e:
                print(f"âŒ [GEMINI_ANALYZER] Fallback load failed: {e}")

        if not self.api_key:
            raise ValueError("Missing GEMINI_API_KEY. Set it in .env file.")
        
        self.model_name = model_name
        self.client = genai.Client(api_key=self.api_key)
        self.uploader = GeminiFileUploader(api_key=self.api_key)
        
        # Initialize JSON parser with Pydantic schema
        self.json_parser = JsonOutputParser(pydantic_object=VideoAnalysisResult)
        
        print(f"âœ… [GEMINI_ANALYZER] Initialized with model: {model_name}")
    
    def analyze_video(self, video_path: str, cleanup_after: bool = True) -> Dict:
        """
        PhÃ¢n tÃ­ch video vÃ  tráº£ vá» structured result.
        
        Args:
            video_path: ÄÆ°á»ng dáº«n file video local
            cleanup_after: XÃ³a file khá»i Gemini sau khi phÃ¢n tÃ­ch xong
        
        Returns:
            {
                "success": True/False,
                "analysis": VideoAnalysisResult (dict format),
                "file_uri": "files/...",
                "processing_time_ms": int,
                "error": str (náº¿u tháº¥t báº¡i)
            }
        """
        start_time = time.time()
        
        print(f"\n{'='*60}")
        print(f"ğŸ¬ [GEMINI_ANALYZER] Starting Video Analysis")
        print(f"{'='*60}")
        print(f"   Video: {os.path.basename(video_path)}")
        print(f"   Model: {self.model_name}")
        
        file_name = None
        
        try:
            # Step 1: Upload video to Gemini
            print(f"\nğŸ“¤ Step 1: Uploading video to Gemini...")
            upload_result = self.uploader.upload_video(video_path)
            
            if not upload_result.get("success"):
                raise GeminiUploadError(f"Upload failed: {upload_result.get('error')}")
            
            file_uri = upload_result["file_uri"]
            file_name = upload_result["file_name"]
            print(f"   âœ… Uploaded: {file_uri}")
            
            # Step 2: Build prompt with format instructions
            print(f"\nğŸ“ Step 2: Building analysis prompt...")
            format_instructions = self.json_parser.get_format_instructions()
            prompt = ANALYSIS_PROMPT_TEMPLATE.format(format_instructions=format_instructions)
            
            # Step 3: Call Gemini with video + prompt
            print(f"\nğŸ¤– Step 3: Calling Gemini for analysis...")
            
            # Create file reference for the uploaded video
            video_file = self.client.files.get(name=file_name)
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[
                    types.Content(
                        role="user",
                        parts=[
                            types.Part.from_uri(
                                file_uri=video_file.uri,
                                mime_type=video_file.mime_type
                            ),
                            types.Part.from_text(text=prompt)
                        ]
                    )
                ],
                    config=types.GenerateContentConfig(
                        temperature=0.2,
                        max_output_tokens=8192,
                        system_instruction=SYSTEM_INSTRUCTION
                    )
            )
            
            # Step 4: Parse response
            print(f"\nğŸ“Š Step 4: Parsing response...")
            response_text = response.text
            
            # Try to extract JSON from response
            analysis_dict = self._extract_json(response_text)
            
            # Validate with Pydantic
            analysis = VideoAnalysisResult.model_validate(analysis_dict)
            
            # Calculate time range seconds if missing
            analysis_dict = self._enrich_time_data(analysis.model_dump())
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            print(f"\n{'='*60}")
            print(f"âœ… [GEMINI_ANALYZER] Analysis Complete!")
            print(f"{'='*60}")
            print(f"   Title: {analysis_dict['general_info']['title']}")
            print(f"   Category: {analysis_dict['general_info']['category']}")
            print(f"   Viral Score: {analysis_dict['virality_factors']['score']}/10")
            print(f"   Segments: {len(analysis_dict['script_breakdown'])}")
            print(f"   Time: {processing_time_ms}ms")
            
            # Cleanup
            if cleanup_after and file_name:
                self.uploader.delete_file(file_name)
            
            return {
                "success": True,
                "analysis": analysis_dict,
                "file_uri": file_uri,
                "processing_time_ms": processing_time_ms,
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            import traceback
            print(f"\nâŒ [GEMINI_ANALYZER] Error: {e}")
            traceback.print_exc()
            
            # Try cleanup on error
            if cleanup_after and file_name:
                try:
                    self.uploader.delete_file(file_name)
                except:
                    pass
            
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__,
                "processing_time_ms": int((time.time() - start_time) * 1000)
            }
    
    def _extract_json(self, text: str) -> Dict:
        """
        Extract JSON from response text.
        Handles cases where JSON is wrapped in markdown code blocks.
        """
        # Try direct parse first
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        # Try to find JSON in markdown code block
        patterns = [
            r'```json\s*([\s\S]*?)\s*```',
            r'```\s*([\s\S]*?)\s*```',
            r'\{[\s\S]*\}'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    json_str = match.group(1) if '```' in pattern else match.group(0)
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    continue
        
        raise ValueError(f"Could not extract valid JSON from response: {text[:500]}...")
    
    def _enrich_time_data(self, analysis_dict: Dict) -> Dict:
        """
        Enrich script_breakdown with start_seconds and end_seconds if missing.
        Parses time_range format "MM:SS - MM:SS" to seconds.
        """
        for segment in analysis_dict.get("script_breakdown", []):
            time_range = segment.get("time_range", "")
            
            if segment.get("start_seconds") is None or segment.get("end_seconds") is None:
                try:
                    # Parse "00:15 - 00:30" format
                    parts = time_range.split(" - ")
                    if len(parts) == 2:
                        start_parts = parts[0].strip().split(":")
                        end_parts = parts[1].strip().split(":")
                        
                        start_seconds = int(start_parts[0]) * 60 + int(start_parts[1])
                        end_seconds = int(end_parts[0]) * 60 + int(end_parts[1])
                        
                        segment["start_seconds"] = start_seconds
                        segment["end_seconds"] = end_seconds
                except (ValueError, IndexError):
                    pass
        
        return analysis_dict
    
    def get_analysis_prompt(self) -> str:
        """
        Get the full analysis prompt (for debugging/testing).
        """
        format_instructions = self.json_parser.get_format_instructions()
        return ANALYSIS_PROMPT_TEMPLATE.format(format_instructions=format_instructions)


# ============================================================
# CONVENIENCE FUNCTION
# ============================================================

def analyze_video(video_path: str, api_key: str = None) -> Dict:
    """
    Convenience function to analyze a video.
    
    Args:
        video_path: Path to video file
        api_key: Optional API key
    
    Returns:
        Analysis result dict
    """
    analyzer = GeminiVideoAnalyzer(api_key=api_key)
    return analyzer.analyze_video(video_path)


# ============================================================
# TEST
# ============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª Gemini Video Analyzer Test")
    print("=" * 60)
    
    # Test video path
    test_video = r"E:\Tiktok_content_AI\scraper_data\content_files\tiktok_video_7296055437135252738.mp4"
    
    # Find any MP4 if test video doesn't exist
    if not os.path.exists(test_video):
        scraper_dir = r"E:\Tiktok_content_AI\scraper_data\content_files"
        if os.path.exists(scraper_dir):
            for f in os.listdir(scraper_dir):
                if f.endswith(".mp4"):
                    test_video = os.path.join(scraper_dir, f)
                    break
    
    if os.path.exists(test_video):
        print(f"\nğŸ“¹ Testing with: {os.path.basename(test_video)}")
        print(f"   Size: {os.path.getsize(test_video) / (1024*1024):.1f}MB")
        
        try:
            analyzer = GeminiVideoAnalyzer()
            result = analyzer.analyze_video(test_video)
            
            if result["success"]:
                print(f"\nğŸ“Š Analysis Result:")
                analysis = result["analysis"]
                
                print(f"\nğŸ¬ General Info:")
                print(f"   Title: {analysis['general_info']['title']}")
                print(f"   Category: {analysis['general_info']['category']}")
                print(f"   Sentiment: {analysis['general_info']['overall_sentiment']}")
                
                print(f"\nğŸ“ Script Breakdown ({len(analysis['script_breakdown'])} segments):")
                for seg in analysis['script_breakdown'][:3]:  # Show first 3
                    print(f"   [{seg['time_range']}] {seg['visual_description'][:50]}...")
                
                print(f"\nğŸ”¥ Viral Score: {analysis['virality_factors']['score']}/10")
                print(f"   Reasons: {analysis['virality_factors']['reasons'][:100]}...")
                
                # Save full result
                output_path = r"E:\Tiktok_content_AI\temp\analysis_test_output.json"
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ“ Full result saved to: {output_path}")
                
            else:
                print(f"\nâŒ Analysis failed: {result['error']}")
                
        except Exception as e:
            print(f"\nâŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"âŒ No test video found")
